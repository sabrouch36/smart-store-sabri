
> Use this repo to start a professional Python BI project that reads raw data into pandas DataFrames.

- Course: Business Intelligence
- Instructor: Dr. Denise Case
- Repository Template: <https://github.com/denisecase/pro-analytics-02>
- Author: **Sabri Hamdaoui**, MBA â€“ Data Analytics
- University: Northwest Missouri State University
- GitHub: [sabrouch36](https://github.com/sabrouch36)

---

# Smart Store Data Preparation (P3)

This project prepares raw business data (Customers, Products, and Sales) so it is clean, consistent, and ready for use in analytics and future ETL processes.

## Project Goal
The goal of this phase is to clean and standardize datasets to ensure accuracy and reliability when performing reporting, visualizations, or loading into a central data warehouse.

## Key Tasks Performed
- Removed duplicate records
- Handled missing values using simple fill strategies
- Standardized text fields (trim + lowercase)
- Automatically detected correct name columns
- Removed numeric outliers where appropriate
- Saved cleaned outputs into a `prepared/` data directory

## Files Processed
| Raw Dataset               | Output File                      |
|--------------------------|----------------------------------|
| `customers_data.csv`     | `customers_prepared.csv`         |
| `products_data.csv`      | `products_prepared.csv`          |
| `sales_data.csv`         | `sales_prepared.csv`             |

## Main Script
The primary pipeline is located at:
src/analytics_project/data_prep.py


## The reusable data cleaning helper class is located at:
src/utils/data_scrubber.py


## How to Run
From the project root:

uv sync
uv run python -m analytics_project.data_prep


## Output Location

Cleaned data is stored here:
/data/prepared/

## Logging

All execution logs are stored in:
project.log


Data is now clean and ready for the ETL and analysis steps in upcoming modules.
---

## ğŸ“˜ P4 â€“ Create and Populate Data Warehouse (DW)

### ğŸ¯ Project Overview
In this phase, we designed and implemented a **data warehouse** using SQLite to support business intelligence and analytics.
The project follows the workflow: **Design â†’ Build â†’ Load â†’ Verify â†’ Document**.

### ğŸ§± Schema Design
The warehouse uses a **Star Schema** consisting of:
- **Fact Table:** `sale`
- **Dimension Tables:** `customer`, `product`

Each sale record references a customer and a product, enabling cross-analysis of performance and customer behavior.

**Entity Relationships**
- `sale.customer_id` â†’ `customer.customer_id`
- `sale.product_id` â†’ `product.product_id`

### âš™ï¸ Implementation
The ETL script [`etl_to_dw.py`](src/analytics_project/etl_to_dw.py):
- Creates the SQLite database `smart_sales.db` in `data/dw/`
- Defines tables using SQL `CREATE TABLE` statements
- Loads prepared CSV files from `data/prepared/`
- Removes duplicates, enforces primary and foreign keys
- Commits all data into the warehouse and validates relationships

### ğŸ“Š Verification
After running the script, we verified:
| Table | Row Count | Status |
|--------|------------|---------|
| customer | 200 | âœ… |
| product | 100 | âœ… |
| sale | 1999 | âœ… |

**Foreign Keys:** OK âœ…
**Null / Duplicate Checks:** All Passed âœ…

### ğŸ§ª Example Query (Join)
```sql
SELECT s.sale_id, c.name, p.product_name, s.sale_amount, s.sale_date
FROM sale s
JOIN customer c USING (customer_id)
JOIN product  p USING (product_id)
LIMIT 10;

ğŸ§­ How to Run
python src/analytics_project/etl_to_dw.py
This will recreate the DW schema and reload all prepared data.
```
## ğŸ“¸ Screenshots

![Customer Table](docs/images/customer-sample.png)
![Sale Table](docs/images/sale-sample.png)
![Row Counts](docs/images/dw-rowcounts.png)
![FK Check](docs/images/dw-fkcheck.png)

ğŸ“Š P5 â€“ Cross-Platform Reporting with Power BI
ğŸ¯ Overview

In this phase, we used Power BI Desktop (Windows implementation) to connect to the SQLite data warehouse created in P4, perform OLAP operations, and generate interactive business intelligence reports.

The reporting workflow included:

Connecting Power BI to the SQLite warehouse via ODBC

Importing the customer, product, and sale tables

Cleaning the date column and converting it to a proper Date type

Creating slicers, pivot tables, and charts

Applying slice, dice, and drilldown operations

Producing final visualizations to analyze sales performance by category and region

ğŸ—‚ï¸ Data Model in Power BI

After loading the DW, the following model appeared in Power BI:

sale (fact table)

customer (dimension)

product (dimension)

Relationships were based on:

sale.customer_id â†’ customer.customer_id

sale.product_id â†’ product.product_id

âœ” Relationships created successfully
âœ” Date column cleaned and converted from text to Date
âœ” Error row removed (2023-13-01)

ğŸ” OLAP Operations
1ï¸âƒ£ Slice (Filter by Date)

Using a date slicer, sales were filtered using a specific date range:

Added a Slicer visual

Placed sale_date in the slicer

Set slicer type to Between

Result: shows sales only for the chosen time window
### ğŸ“Œ Slice Operation (Date Filter)

![Slice](docs/images/slice.png)


2ï¸âƒ£ Dice (Category Ã— Region Pivot)

Created a matrix table to analyze sales by:

Rows: product category

Columns: customer region

Values: Sum of sale_amount

This produced a full cross-tab analysis (category Ã— region), including totals.

ğŸ“¸ Matching screenshot:

### ğŸ² Dice Operation (Category Ã— Region)

![Dice](docs/images/dice.png)


3ï¸âƒ£ Drilldown (Chart Visualization)

A clustered column chart was created:

X-axis: region

Legend: category

Y-axis: Sum of sale_amount

This enables:

Visual drilldown by clicking a category

Comparing regions

Seeing category patterns clearly

ğŸ“¸ Matching screenshot:

![drilldown](docs/images/drilldown.png)

ğŸ“ˆ Final Visuals Included

âœ” Slicer for sale_date

âœ” Pivot (matrix) for category Ã— region

âœ” Clustered column chart (drilldown enabled)

âœ” Cleaned and validated data model

ğŸ› ï¸ Tools Used

Power BI Desktop (Windows)

ODBC connection to SQLite (smart_sales.db)

Star schema (fact_sale + dimensions)

ğŸ“„ How to Reproduce

Launch Power BI Desktop

Get Data â†’ ODBC â†’ Select SQLite connection

Load the three DW tables

Convert sale_date column to Date

Create slicer, matrix, and chart

Save report as .pbix

Export screenshots for documentation

ğŸ“¸ Required Submission Images (all completed)


âœ” Slice result (date filter)

âœ” Dice result (category Ã— region matrix)

âœ” Drilldown chart (clustered columns)
